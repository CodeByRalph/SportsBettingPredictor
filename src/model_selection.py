import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score, accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import joblib
from src.features import engineer_features

# model imports
from src.models.linear_regression import train_linear_regression
from src.models.random_forest import train_random_forest
from src.models.xgboost import train_xgboost


def preprocess_data(df, target_stat):
    """
    Preprocesses the data for training, including feature engineering and normalization.
    
    Args:
        df (pd.DataFrame): The cleaned dataset.
    
    Returns:
        X_train, X_test, y_train, y_test: Processed training and test sets.
        scaler: The scaler object used for normalization.
    """
    # Removes Data Column but saves it for use in visualization
    date_col = df['Date']

    df = engineer_features(df, target_stat)

    # Drop irrelevant columns
    df = df.drop(['OPP', 'Date'], axis=1)

    # Drop rows with NaN values generated by rolling and shifting operations
    df = df.dropna()

    # Handle any remaining infinite or very large values
    df = df.replace([np.inf, -np.inf], np.nan)  # Replace inf values with NaN
    df = df.fillna(method='ffill').fillna(method='bfill')

    # Target variable and feature columns
    X = df.drop(target_stat, axis=1)
    y = df[target_stat]
    
     # Log transformation for the YDS stat
    if target_stat == 'YDS' or target_stat == 'YDS2':
        y = np.log1p(y)

    # Normalize the features
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Train-test split
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, shuffle=False, random_state=42)

     # Debugging: Print feature names and shapes before fitting
    # print(f"Number of features in X_train: {X_train.shape[1]}")
    # print(f"Number of features in X_test: {X_test.shape[1]}")
    # print(f"Feature names: {X.columns}")

    return X_train, X_test, y_train, y_test, scaler, date_col


def predict_next_game_for_all_models(models, X_last_game, scaler, target_stat):
    """
    Predicts the target stat for the next game using the trained models.

    Args:
        models (dict): Dictionary of trained models.
        X_last_game (np.array): The feature data of the last game to predict the next game.
    """
    print("\n---------------------------------------")
    print("Predicting next game's target stat for each model:")

    for model_name, model in models.items():
        try:
            # Predict the target stat for the next game
            y_pred = model.predict(X_last_game)

            if target_stat == 'YDS':
                y_pred = np.expm1(y_pred)

            print(f"{model_name} prediction for next game: {np.round(y_pred[0])}")
        except Exception as e:
            print(f"Error in {model_name} during prediction: {e}")
    print("\n---------------------------------------")


def evaluate_model(model, X_test, y_test, target_stat):
    try:
        y_pred = model.predict(X_test)

        # Revert log transformation for YDS
        if target_stat == 'YDS':
            y_pred = np.expm1(y_pred)
            y_test = np.expm1(y_test)

        print(f"Predictions:   {np.round(y_pred).astype(int)}")
        print(f"Actual values: {np.round(y_test.values).astype(int)}")

        # Ensure the lengths of y_pred and y_test match
        if len(y_pred) != len(y_test):
            raise ValueError(f"Length mismatch: y_pred has {len(y_pred)} elements, y_test has {len(y_test)} elements")


        # # Print predictions vs actual values
        # print("Predicted vs Actual values:")
        # for i in range(len(y_test)):
        #     try:
        #         print(f"Loop Iteration {i}")
        #         print(f"Predicted: {y_pred[i]}, Actual: {y_test.iloc[i]}")  # Use .iloc for proper indexing
        #     except Exception as loop_error:
        #         print(f"Error during loop iteration {i}: {loop_error}")

        # Calculate accuracy by comparing rounded predictions to actual values
        try:
            accuracy = accuracy_score(y_test.astype(int), np.round(y_pred).astype(int))
            print(f"\nAccuracy: {accuracy * 100:.2f}%")
        except Exception as e:
            print(f"Error calculating Accuracy_score: {e}")

        # Calculate Mean Squared Error
        try:
            mse = mean_squared_error(y_test, y_pred)
            print(f"Mean Squared Error (MSE): {mse}")
        except Exception as e:
            print(f"Error calculating MSE: {e}")

        # Calculate Root Mean Squared Error (optional)
        try:
            rmse = np.sqrt(mse)
            print(f"Root Mean Squared Error (RMSE): {rmse}")
        except Exception as e:
            print(f"Error calculating RMSE: {e}")

        # Calculate R² score (optional)
        try:
            r2 = r2_score(y_test, y_pred)
            print(f"R² Score: {r2}")
        except Exception as e:
            print(f"Error calculating R² score: {e}")
    except Exception as e:
        print(f"Error occurred during model evaluation: {e}")


def test_model_performance(player_id, target_stat):
    data_file_path = os.path.join('data', 'processed', f'player_{player_id}_clean.csv')
    df = pd.read_csv(data_file_path)

    X_train, X_test, y_train, y_test, scaler, date_col = preprocess_data(df, target_stat)

    # Train and evaluate multiple models
    models = {
        'RandomForest': train_random_forest(X_train, y_train),
        'XGBoost': train_xgboost(X_train, y_train),
        'LinearRegression': train_linear_regression(X_train, y_train)
    }

    feature_names = df.drop(target_stat, axis=1).columns

    for model_name, model in models.items():
        print('\n---------------------------------------')
        print(f"Evaluating {model_name}...")
        evaluate_model(model, X_test, y_test, target_stat)
    
        if hasattr(model, 'feature_importances_'):
            print(f"Plotting feature importances for {model_name}")
            
            # Get the feature importances and sort them
            importances = model.feature_importances_
            sorted_indices = np.argsort(importances)[::-1]
            # Select the top N indices
            top_indices = sorted_indices[:15]

            # Use these indices to get the top N feature names and their importances
            top_features = pd.DataFrame({
                'Feature': np.array(feature_names)[top_indices],
                'Importance': importances[top_indices]
            })

            # Create a horizontal bar chart
            plt.figure(figsize=(10, 6))
            plt.barh(top_features['Feature'], top_features['Importance'], color='skyblue')
            plt.xlabel('Importance')
            plt.ylabel('Feature')
            plt.title(f'Feature Importance for {model_name}')
            plt.gca().invert_yaxis()  # Invert y-axis to have the most important feature at the top
            plt.tight_layout()

            # Save the plot to a file instead of showing it
            output_path = f"feature_importance_{model_name}.png"
            plt.savefig(output_path)
            print(f"Feature importance plot saved as {output_path}")

            plt.close() 

    # Predict the next game using the most recent game's features
    X_last_game = X_test[-1].reshape(1, -1)
    predict_next_game_for_all_models(models, X_last_game, scaler, target_stat)